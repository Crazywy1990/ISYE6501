> set.seed(1)
> 
> #install.packages("glmnet")
> 
> library(glmnet)
> 
> mydata = as.data.frame(read.table("uscrime.txt", header = TRUE)) #read in data
> sc_data = as.matrix(mydata)
> for (i in 1:15) { #scale predictors
+   sc_data[, i] = (mydata[, i] - min(mydata[, i])) / (max(mydata[, i]) -
+                                                        min(mydata[, i]))
+ }
> 
> predictors = sc_data[,1:15]
> response = sc_data[, 16]
> resultsmin = matrix(, 19, 2)
> colnames(resultsmin) = c('alpha', 'lambda.min')
> results1se = matrix(, 19, 2)
> colnames(results1se) = c('alpha', 'lambda.1se')
> 
> i = 1
> for (a in seq(.05,.95,.05)) {
+ enet = cv.glmnet(
+   predictors,
+   response,
+   family = "gaussian",
+   alpha = a,
+   nfolds = 5,
+   type.measure = "mse"
+ )
+ 
+ devmin = enet$glmnet.fit$dev.ratio[which(enet$glmnet.fit$lambda == enet$lambda.min)]
+ dev1se = enet$glmnet.fit$dev.ratio[which(enet$glmnet.fit$lambda == enet$lambda.1se)]
+ 
+ resultsmin[i,1] = a
+ resultsmin[i,2] = devmin
+ results1se[i,1] = a
+ results1se[i,2] = dev1se
+ 
+ i= i+1
+ }
> 
> cbind(resultsmin, results1se)
      alpha lambda.min alpha lambda.1se
 [1,]  0.05  0.7600097  0.05  0.6112904
 [2,]  0.10  0.7535046  0.10  0.6510103
 [3,]  0.15  0.7719830  0.15  0.6424259
 [4,]  0.20  0.7446501  0.20  0.5150635
 [5,]  0.25  0.7521779  0.25  0.5962289
 [6,]  0.30  0.7849256  0.30  0.6079146
 [7,]  0.35  0.7728548  0.35  0.5976618
 [8,]  0.40  0.7723386  0.40  0.4698605
 [9,]  0.45  0.7675174  0.45  0.6930689
[10,]  0.50  0.7262310  0.50  0.4532806
[11,]  0.55  0.7837526  0.55  0.7010773
[12,]  0.60  0.7870555  0.60  0.7319783
[13,]  0.65  0.6951777  0.65  0.4001932
[14,]  0.70  0.7205195  0.70  0.5835926
[15,]  0.75  0.7770456  0.75  0.7010699
[16,]  0.80  0.7039714  0.80  0.5408690
[17,]  0.85  0.7665348  0.85  0.6603967
[18,]  0.90  0.7432739  0.90  0.6166792
[19,]  0.95  0.7866508  0.95  0.7208391
> best_alpha = matrix(, 2, 2)
> colnames(best_alpha) = c('alpha', 'lambda')
> rownames(best_alpha) = c('.min', '.1se')
> best_alpha[1,] = resultsmin[which.max(resultsmin[,2]),]
> best_alpha[2,] = results1se[which.max(results1se[,2]),]
> best_alpha
     alpha    lambda
.min   0.6 0.7870555
.1se   0.6 0.7319783
> 
> 
> r = nrow(sc_data)
> set = sample(1:r, size = round(r * .8), replace = FALSE)
> train = sc_data[set,]
> test = sc_data[-set,]
> 
> 
> #Using the lambda.min model
> enetmin = cv.glmnet(
+   predictors,
+   response,
+   family = "gaussian",
+   alpha = best_alpha[1,1],
+   nfolds = 5,
+   type.measure = "mse")
> coef(enetmin, s = enetmin$lambda.min)
16 x 1 sparse Matrix of class "dgCMatrix"
                      1
(Intercept) -293.041269
M            414.868525
So            46.301462
Ed           439.007442
Po1         1088.142151
Po2           87.404209
LF             0.177451
M.F          284.530645
Pop            .       
NW            60.880746
U1          -195.708421
U2           379.046332
Wealth        93.871025
Ineq         726.763583
Prob        -427.527884
Time           .       
> 
> 
> model = lm(Crime~M+So+Ed+Po1+Po2+LF+M.F+NW+U1+U2+Ineq+Prob, as.data.frame(train))
> summary(model)

Call:
lm(formula = Crime ~ M + So + Ed + Po1 + Po2 + LF + M.F + NW + 
    U1 + U2 + Ineq + Prob, data = as.data.frame(train))

Residuals:
    Min      1Q  Median      3Q     Max 
-412.18  -80.81    5.34  105.83  470.58 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)  -456.72     275.59  -1.657  0.10997   
M             305.87     266.97   1.146  0.26276   
So            -89.53     174.93  -0.512  0.61326   
Ed            787.32     248.44   3.169  0.00401 **
Po1          1906.05    1349.75   1.412  0.17023   
Po2          -677.44    1423.49  -0.476  0.63828   
LF           -214.30     256.55  -0.835  0.41145   
M.F           298.62     258.71   1.154  0.25930   
NW            375.30     354.04   1.060  0.29925   
U1           -323.95     343.38  -0.943  0.35450   
U2            487.38     347.98   1.401  0.17362   
Ineq         1065.41     288.39   3.694  0.00108 **
Prob         -401.72     209.30  -1.919  0.06643 . 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 205.4 on 25 degrees of freedom
Multiple R-squared:  0.8165,	Adjusted R-squared:  0.7284 
F-statistic: 9.268 on 12 and 25 DF,  p-value: 1.804e-06

> pred = predict.lm(model, as.data.frame(test))
> sse = sum((pred - test[,16]) ^ 2)
> sst = sum((test[,16] - mean(test[,16])) ^ 2) #total sum of squares
> 1 - sse / sst
[1] 0.4987092
> 
> #Using the lambda.1se model
> enet1se = cv.glmnet(
+   predictors,
+   response,
+   family = "gaussian",
+   alpha = best_alpha[2,1],
+   nfolds = 5,
+   type.measure = "mse")
> coef(enet1se, s = enet1se$lambda.1se)
16 x 1 sparse Matrix of class "dgCMatrix"
                     1
(Intercept)  335.94369
M            188.16200
So             .      
Ed            22.37253
Po1          758.72949
Po2          332.62180
LF             .      
M.F          257.77357
Pop            .      
NW            57.20927
U1             .      
U2             .      
Wealth         .      
Ineq         278.27325
Prob        -284.99831
Time           .      
> 
> model1se = lm(Crime~M+Ed+Po1+Po2+M.F+NW+Ineq+Prob, as.data.frame(train))
> summary(model1se)

Call:
lm(formula = Crime ~ M + Ed + Po1 + Po2 + M.F + NW + Ineq + Prob, 
    data = as.data.frame(train))

Residuals:
    Min      1Q  Median      3Q     Max 
-401.21 -103.39  -10.02  108.34  459.84 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   -394.4      232.0  -1.700  0.09990 .  
M              199.9      234.2   0.853  0.40053    
Ed             572.4      209.7   2.729  0.01069 *  
Po1           1754.6     1285.2   1.365  0.18268    
Po2           -307.2     1346.2  -0.228  0.82108    
M.F            209.5      181.8   1.152  0.25862    
NW             320.2      280.6   1.141  0.26322    
Ineq          1017.6      267.1   3.809  0.00067 ***
Prob          -400.7      190.0  -2.109  0.04370 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 202.7 on 29 degrees of freedom
Multiple R-squared:  0.7927,	Adjusted R-squared:  0.7355 
F-statistic: 13.86 on 8 and 29 DF,  p-value: 4.815e-08

> pred1se = predict.lm(model1se, as.data.frame(test))
> sse1se = sum((pred1se - test[,16]) ^ 2)
> sst1se = sum((test[,16] - mean(test[,16])) ^ 2) #total sum of squares
> 1 - sse1se / sst1se
[1] 0.4418632