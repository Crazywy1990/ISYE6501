setwd("C:/Users/Bryson/Desktop")
setwd("C:/Users/Bryson/Desktop")
# Setup
rm(list=ls())
library(kernlab)
library(kknn)
library(e1071)
cardData<-read.table("credit_card_data.txt",stringsAsFactors = FALSE, header=FALSE)
irisData<-read.table('iris.txt',header = TRUE)
# Question 3.1.a
# To solve this problem, I iterated through about 10,000 combinations of k
# and kvc ranging from 2-100 and checked the accuracy of each.  The optimal
# values that I found were for a k=100 and kcv=6 giving almost an 86%
# accuracy.
set.seed(1)
kfolds<-2
kneighbors<-2
bestpred<-0
bestkneighbor<-0
bestkfolds<-0
while (kfolds<=100) {
while (kneighbors<=100) {
kknn_model2<-cv.kknn(V11~.,cardData,kcv=kfolds,k=kneighbors,kernel="gaussian")
kknn_model2_predicted<-round(kknn_model2[[1]][,2])
if (bestpred<sum(kknn_model2_predicted==cardData$V11)/nrow(cardData)) {
bestpred=sum(kknn_model2_predicted==cardData$V11)/nrow(cardData)
bestkneighbors=kneighbors
bestkfolds=kfolds
}
kneighbors=kneighbors+1
}
kfolds=kfolds+1
kneighbors=2
}
print(bestkneighbors)
print(bestkfolds)
print(bestpred) # Shows the prediction accuracy for k=6 which is approx. 86%
# Question 3.1.b
train_percent<-0.5
val_percent<-0.3
test_percent<-0.2
tvt.sampling<-sample(x=3,size=nrow(cardData)
,replace=T
,prob=c(train_percent
,val_percent,test_percent))
kknn_train<-cardData[tvt.sampling==1,]
kknn_val<-cardData[tvt.sampling==2,]
kknn_test<-cardData[tvt.sampling==3,]
kknn_model13a<-kknn(V11~.,train=kknn_train,test=kknn_val,k=10,kernel="gaussian")
kknn_model13b<-kknn(V11~.,train=kknn_train,test=kknn_val,k=2,kernel="triangular")
accuracy3a<-sum(round(fitted.values(kknn_model13a))==kknn_val[,11])/nrow(kknn_val)
accuracy3b<-sum(round(fitted.values(kknn_model13b))==kknn_val[,11])/nrow(kknn_val)
accuracy3a #accuracy of 3a against validation data
accuracy3b #accuracy of 3b against validation data
kknn_model13c<-kknn(V11~.,train=kknn_train,test=kknn_test,k=10,kernel="gaussian")
accuracy3c<-sum(round(fitted.values(kknn_model13c))==kknn_test[,11])/nrow(kknn_val)
accuracy3c #accuracy of 3a against test data (i.e., a more realistic accuracy for 3a)
kknn_model13d<-kknn(V11~.,train=kknn_train,test=kknn_test,k=6,kernel="gaussian")
accuracy3d<-sum(round(fitted.values(kknn_model13d))==kknn_test[,11])/nrow(kknn_val)
accuracy3d #checked the accuracy of the values from the first part of the question
# Question 4.1
# Market analysis seems like it would benefit greatly from clustering algorithms.
# For instance, a company could use a clustering algorithm based upon age,
# gender, and spending frequency to cluster past customers into one of two groups,
# (assuming the company had access to that valuable information). The company
# could then create two marketing campaigns: one for each of the groups defined
# in the clustering algorithm.  The idea here is that the two campaigns could be
# better aligned to a diverse customer demographic than a single one trying to
# appeal to both. The same should be true for creating another group, (i.e., a
# third cluster), in that it could make the campaign even better targeted. Taken to
# the extreme, a very large number of campaigns for a very large amount of
# clusters would become impractical quickly. The art would then become figuring
# out how best to optimize the efficiency of the algorithm in targeting potential
# customers in light of the aforementioned trade off.
# Question 4.2
# For this question, I just scaled the data and tested the efficacy of a few
# variations of the kmeans algorithm in correctly classifying the species.
# What I found interesting was that the omission of sepal.length improved
# the effectiveness of the algorithm substantially. Increasing the number of
# clusters and playing with nstart had either no effect or a negative effect
# on the efficacy of the algorithm.
table(irisData[,5], irisData$Species)
set.seed(1)
scdata<-irisData
for (i in 1:4) {
scdata[,i]<-(irisData[,i]-min(irisData[,i]))/(max(irisData[,i])-min(irisData[,i]))
}
irisClusterALLsc1<-kmeans(scdata[,1:4], 3, nstart=20)
table(irisClusterALLsc1$cluster, irisData$Species)
irisClusterALLsc2<-kmeans(scdata[,2:4], 3, nstart=20)
table(irisClusterALLsc2$cluster, irisData$Species) # There is a big gain in accuracy here
irisClusterALLsc3<-kmeans(scdata[,2:4], 3, nstart=1)
table(irisClusterALLsc3$cluster, irisData$Species)
irisClusterALLsc4<-kmeans(scdata[,2:4], 3, nstart=200)
table(irisClusterALLsc4$cluster, irisData$Species)
irisClusterALLsc5<-kmeans(scdata[,2:4], 4, nstart=1)
table(irisClusterALLsc5$cluster, irisData$Species)
setwd("~/Bryson/Github/ISYE6501/Homework 2")
source('~/Bryson/Github/ISYE6501/Homework 2/HW-3dot1b.R', echo=TRUE)
source('~/Bryson/Github/ISYE6501/Homework 2/HW2.R', echo=TRUE)
install.packages("e1071")
source('~/Bryson/Github/ISYE6501/Homework 2/HW2.R', echo=TRUE)
# Setup
rm(list=ls())
library(kernlab)
library(kknn)
library(e1071)
cardData<-read.table("credit_card_data.txt",stringsAsFactors = FALSE, header=FALSE)
irisData<-read.table('iris.txt',header = TRUE)
table(irisData[,5], irisData$Species)
set.seed(1)
scdata<-irisData
for (i in 1:4) {
scdata[,i]<-(irisData[,i]-min(irisData[,i]))/(max(irisData[,i])-min(irisData[,i]))
}
irisClusterALLsc1<-kmeans(scdata[,1:4], 3, nstart=20)
table(irisClusterALLsc1$cluster, irisData$Species)
irisClusterALLsc2<-kmeans(scdata[,2:4], 3, nstart=20)
table(irisClusterALLsc2$cluster, irisData$Species) # There is a big gain in accuracy here
irisClusterALLsc3<-kmeans(scdata[,2:4], 3, nstart=1)
table(irisClusterALLsc3$cluster, irisData$Species)
irisClusterALLsc4<-kmeans(scdata[,2:4], 3, nstart=200)
table(irisClusterALLsc4$cluster, irisData$Species)
irisClusterALLsc5<-kmeans(scdata[,2:4], 4, nstart=1)
table(irisClusterALLsc5$cluster, irisData$Species)
irisClusterALLsc5<-kmeans(scdata[,3:4], 4, nstart=1)
table(irisClusterALLsc5$cluster, irisData$Species)
irisClusterALLsc5<-kmeans(scdata[,3:4], 3, nstart=1)
table(irisClusterALLsc5$cluster, irisData$Species)
# Define the formula for the model, predict R1 based on all other variables.
formula = as.formula(R1~A1+A2+A3+A8+A9+A10+A11+A12+A14+A15)
source('~/Bryson/Github/ISYE6501/Homework 2/HW2 Review.R', echo=TRUE)
