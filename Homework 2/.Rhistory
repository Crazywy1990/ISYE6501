install.packages("ggplot2")
library(ggplot)
library(ggplot2)
library(stats)
library(ggplot2)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
mydata = data.frame(read.table("iris.txt", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
setwd("~/Bryson/Github/ISYE6501/Homework 2")
#install.packages("ggplot2")
library(stats)
library(ggplot2)
rm(list = ls())
mydata = data.frame(read.table("iris.txt", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
distance[x, ] = km$tot.withinss
}
rm(list = ls())
mydata = data.frame(read.table("iris.txt", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
mydata = data.frame(read.table("iris.txt", header = True))
mydata = data.frame(read.table("iris.txt", header = TRUE))
mydata = data.frame(read.table("iris.txt", header = TRUE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
mydata = data.frame(read.table("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
mydata = data.frame(read.table("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
help("rownames")
mydata = data.frame(read.table("iris.csv", header = TRUE)) #read in data
#mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
mydata
View(mydata)
mydata = data.frame(read.frame("iris.csv", header = TRUE)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
View(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
View(training)
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
help("read.csv")
mydata = data.frame(read.csv("iris.csv", header = TRUE,row.names))
mydata = data.frame(read.csv("iris.csv", header = TRUE,,,,row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUE,,,,,row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUE,,,,,row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUEsep = "", quote = "\"'",
dec = ".", numerals = c("allow.loss", "warn.loss", "no.loss"),
row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUEsep = "", quote = "\"'",
dec = ".", numerals = c("allow.loss", "warn.loss", "no.loss"),
row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUEsep = "", quote = "\"'",dec = ".", numerals = c("allow.loss", "warn.loss", "no.loss"),row.names)) #read in data
mydata = data.frame(read.csv("iris.csv", header = TRUE,sep = "", quote = "\"'",dec = ".", numerals = c("allow.loss", "warn.loss", "no.loss"),row.names)) #read in data
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,2:4])
View(training)
View(mydata)
response = data.frame(mydata[, 6])
training = data.matrix(mydata[,2:5])
ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
#mydata = mydata[-1,-1]
#rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 6])
training = data.matrix(mydata[,2:5])
help(kmeans)
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[,2:5])
ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Run clustering with all 4 predictors:
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
sc_train = training
for (i in 1:4){
sc_train[,i] = (training[,i]-min(training[,i]))/(max(training[,i])-min(training[,i]))
}
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[,2:5])
# ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
# ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Need to scale the data
sc_train = training
for (i in 1:4){
sc_train[,i] = (training[,i]-min(training[,i]))/(max(training[,i])-min(training[,i]))
}
#Run clustering with all 4 predictors:
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
View(resp)
table(resp[,2],training$Species)
table(resp[,2],response$Species)
table(resp[,2],response)
View(response)
View(resp)
View(response)
clusters = seq(1, 10)
resp = data.frame(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
}
table(resp[,2],response)
table(resp[,2],mydata$Species)
clusters = seq(1, 10)
resp = data.frame(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
table(resp[,x],mydata$Species)
}
for (x in clusters) {
table(resp[,x],mydata$Species)
}
table(resp[,2],mydata$Species)
table(resp[,2],mydata$Species)
table(resp[,3],mydata$Species)
table(resp[,4],mydata$Species)
table(resp[,5],mydata$Species)
table(resp[,6],mydata$Species)
table(resp[,7],mydata$Species)
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
set.seed(1)
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[, 2:5])
# ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
# ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Need to scale the data
sc_train = training
for (i in 1:4) {
sc_train[, i] = (training[, i] - min(training[, i])) / (max(training[, i]) -
min(training[, i]))
}
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 10)
resp = data.frame(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
table(resp[,x],mydata$Species)
}
table(resp[,2],mydata$Species)
table(resp[,3],mydata$Species)
table(resp[,4],mydata$Species)
table(resp[,5],mydata$Species)
table(resp[,6],mydata$Species)
table(resp[,7],mydata$Species)
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
set.seed(1)
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[, 2:5])
# ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
# ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Need to scale the data
sc_train = training
for (i in 1:4) {
sc_train[, i] = (training[, i] - min(training[, i])) / (max(training[, i]) -
min(training[, i]))
}
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 10)
resp = data.frame(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
table(resp[,x],mydata$Species)
}
table(resp[,2],mydata$Species)
table(resp[,3],mydata$Species)
table(resp[,4],mydata$Species)
table(resp[,5],mydata$Species)
table(resp[,6],mydata$Species)
table(resp[,7],mydata$Species)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
#install.packages("ggplot2")
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
set.seed(1)
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[, 2:5])
# ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
# ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Need to scale the data
sc_train = training
for (i in 1:4) {
sc_train[, i] = (training[, i] - min(training[, i])) / (max(training[, i]) -
min(training[, i]))
}
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, iter.max = 10, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
table(resp[,x],mydata$Species)
}
table(resp[,2],mydata$Species)
table(resp[,3],mydata$Species)
table(resp[,4],mydata$Species)
table(resp[,5],mydata$Species)
table(resp[,6],mydata$Species)
table(resp[,7],mydata$Species)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
#install.packages("ggplot2")
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
set.seed(1)
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[, 2:5])
# ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
# ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
#Need to scale the data
sc_train = training
for (i in 1:4) {
sc_train[, i] = (training[, i] - min(training[, i])) / (max(training[, i]) -
min(training[, i]))
}
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
table(resp[,x],mydata$Species)
}
table(resp[,2],mydata$Species)
table(resp[,3],mydata$Species)
table(resp[,4],mydata$Species)
table(resp[,5],mydata$Species)
table(resp[,6],mydata$Species)
table(resp[,7],mydata$Species)
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = resp[,7]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[,7]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[,7]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[,7]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[,4]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[,4]))+geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species))+geom_point()
ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species))+geom_point()
View(sc_train)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
#install.packages("ggplot2")
library(stats)
library(ggplot2)
rm(list = ls())
cat("\014")
set.seed(1)
mydata = data.frame(read.csv("iris.csv", header = TRUE)) #read in data
response = data.frame(mydata[, 6])
training = data.matrix(mydata[, 2:5])
#Need to scale the data
sc_train = training
for (i in 1:4) {
sc_train[, i] = (training[, i] - min(training[, i])) / (max(training[, i]) -
min(training[, i]))
}
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(sc_train), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train, x, nstart = 20)
resp[, x] = km$cluster
distance[x,] = km$tot.withinss
}
#Comparing the clusters with the known species (though we wouldn't know the actual answer in real life clustering situations)
table(resp[, 2], mydata$Species)
table(resp[, 3], mydata$Species)
table(resp[, 4], mydata$Species)
table(resp[, 5], mydata$Species)
table(resp[, 6], mydata$Species)
table(resp[, 7], mydata$Species)
#Using all four measurements as predictors doesn't really seem to give us much useful information.
#We can keep adding clusters and the clusters will mostly get smaller, but it doesn't actually pertain to much,
#since we have the real data to compare it to.
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[, 4])) + geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[, 4])) + geom_point()
# Plotting out the data vs the known responses shows that the Sepal measurements do not provide a good grouping,
# but the Petal measurements are excellent.  We will redo the previous model creation with only these two predictors.
# We will also only use up to 5 clusters
ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggplot(mydata, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point()
#Run clustering with all 4 predictors.  "1" cluster isn't really applicable, but it helps with the for loop:
clusters = seq(1, 5)
resp1 = matrix(, nrow = nrow(sc_train), ncol = length(clusters))
distance1 = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(sc_train[, 3:4], x, nstart = 20)
resp1[, x] = km$cluster
distance1[x,] = km$tot.withinss
}
table(resp[, 2], mydata$Species)
table(resp[, 3], mydata$Species)
table(resp[, 4], mydata$Species)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[, 2])) + geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[, 3])) + geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp[, 4])) + geom_point()
View(sc_train)
View(sc_train)
table(resp1[, 2], mydata$Species)
table(resp1[, 3], mydata$Species)
table(resp1[, 4], mydata$Species)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 2])) + geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 3])) + geom_point()
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 4])) + geom_point()
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
help(ggsave)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 2])) + geom_point()
ggsave("2 Clusters.pdf", width = 5, height = 5)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 3])) + geom_point()
ggsave("3 Clusters.pdf", width = 5, height = 5)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 4])) + geom_point()
ggsave("4 Clusters.pdf", width = 5, height = 5)
ggsave("2 Clusters.pdf", width = 8.5, height = 11, units = c("in"))
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 2])) + geom_point()
ggsave(
"2 Clusters.jpeg",
width = 6,
height = 4,
units = c("in")
)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 3])) + geom_point()
ggsave(
"3 Clusters.jpeg",
width = 6,
height = 4,
units = c("in")
)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = resp1[, 4])) + geom_point()
ggsave(
"4 Clusters.jpeg",
width = 6,
height = 4,
units = c("in")
)
ggplot(mydata, aes(Petal.Length, Petal.Width, color = Species)) + geom_point()
ggsave(
"Real Response.jpeg",
width = 6,
height = 4,
units = c("in")
)
source('~/Bryson/Github/ISYE6501/Homework 2/HW-4dot1.R', echo=TRUE)
