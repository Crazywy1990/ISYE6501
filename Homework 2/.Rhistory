accuracy = total / nrow(validation)
answery[z, 2] = accuracy
z = z + 1
}
steps = seq(1, 25)
answery = matrix(,nrow = length(steps),ncol = 2)
z = 1
for (y in steps) {
answerx = matrix(, nrow = nrow(validation), ncol = 1)
for (x in 1:nrow(validation)) {
knn = kknn(V11 ~ .,
training,
validation[x, ],
k = y,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == validation[x, 11]
answerx[x, 1] = match
total = sum(answerx)
}
answery[z, 1] = y
accuracy = total / nrow(validation)
answery[z, 2] = accuracy
z = z + 1
}
View(answery)
Best_K_Value_validation = which.max(rowMeans(answery))  #This will chose the training set with the higherst accuracy, thus the best K-NN Value
Best_K_Value_validation
for (y in steps) {
answerx = matrix(, nrow = nrow(validation), ncol = 1)
for (x in 1:nrow(validation)) {
knn = kknn(V11 ~ .,
training,
validation[x, ],
k = y,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == validation[x, 11]
answerx[x, 1] = match
total = sum(answerx)
}
answery[z, 1] = y
accuracy = total / nrow(validation)
answery[z, 2] = accuracy
z = z + 1
}
Best_K_Value_validation = which.max(rowMeans(answery))  #This will chose the training set with the higherst accuracy, thus the best K-NN Value
Best_K_Value_validation
#install.packages("kknn")
library(kknn)
rm(list = ls())
mydata = data.frame(read.csv("credit_card_data.csv", header = FALSE)) #read in data
training = data.frame()
validation = data.frame()
test = data.frame()
df = data.frame()
count = 1
for (x in 1:nrow(mydata)) {
#using rotation to put the 80% of the data into a training set and 10% each into validation and testing sets
df = mydata[x, ]
if (count >= 11) {
count = 1
}
if (count <= 8) {
training = rbind(training,df)
#training[nrow(training) + 1, ] = df
}  else if (count == 9) {
validation = rbind(validation,df)
#validation[nrow(validation) + 1, ] = df
}  else if (count == 10) {
test = rbind(test,df)
#test[nrow(test) + 1, ] = df
}
count = count + 1
}
steps = seq(1, 50)
answery = matrix(,nrow = length(steps),ncol = 2)
z = 1
for (y in steps) {
answerx = matrix(, nrow = nrow(validation), ncol = 1)
for (x in 1:nrow(validation)) {
knn = kknn(V11 ~ .,
training,
validation[x, ],
k = y,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == validation[x, 11]
answerx[x, 1] = match
total = sum(answerx)
}
answery[z, 1] = y
accuracy = total / nrow(validation)
answery[z, 2] = accuracy
z = z + 1
}
Best_K_Value_validation = which.max(rowMeans(answery))  #This will chose the training set with the higherst accuracy, thus the best K-NN Value
Best_K_Value_validation
View(answery)
Best_K_Value_validation = which.max(answery[,2])
Best_K_Value_validation
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 3.1b
#install.packages("kknn")
library(kknn)
rm(list = ls())
mydata = data.frame(read.csv("credit_card_data.csv", header = FALSE)) #read in data
training = data.frame()
validation = data.frame()
test = data.frame()
df = data.frame()
count = 1
for (x in 1:nrow(mydata)) {
#using rotation to put the 80% of the data into a training set and 10% each into validation and testing sets
df = mydata[x, ]
if (count >= 11) {
count = 1
}
if (count <= 8) {
training = rbind(training,df)
#training[nrow(training) + 1, ] = df
}  else if (count == 9) {
validation = rbind(validation,df)
#validation[nrow(validation) + 1, ] = df
}  else if (count == 10) {
test = rbind(test,df)
#test[nrow(test) + 1, ] = df
}
count = count + 1
}
steps = seq(1, 50)
answery = matrix(,nrow = length(steps),ncol = 2)
z = 1
for (y in steps) {
answerx = matrix(, nrow = nrow(validation), ncol = 1)
for (x in 1:nrow(validation)) {
knn = kknn(V11 ~ .,
training,
validation[x, ],
k = y,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == validation[x, 11]
answerx[x, 1] = match
total = sum(answerx)
}
answery[z, 1] = y
accuracy = total / nrow(validation)
answery[z, 2] = accuracy
z = z + 1
}
Best_K_Value_validation = which.max(answery[,2])  #This will chose the training set with the higherst accuracy, thus the best K-NN Value
Best_K_Value_validation
answerx = matrix(, nrow = nrow(test), ncol = 1)
for (x in 1:nrow(test)) {
knn = kknn(V11 ~ .,
training,
test[x, ],
k = Best_K_Value_validation,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == test[x, 11]
answerx[x, 1] = match
test_accuracy = sum(answerx)/ nrow(test)
}
test_accuracy
install.packages("kmeans")
install.packages("kmeans.ddR")
rm(list = ls())
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
library(stats)
library(stats)
rm(list = ls())
help(kmeans)
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
response = mydata[,6]
response = data.frame(mydata[,6])
mydata = mydata[,-6]
training = mydata[,-6]
clusters = seq(1,10)
km = kmeans(training, 5, iter.max = 10, nstart = 1)
training = matrix(mydata[,-6])
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
response = data.frame(mydata[,6])
training = matrix(mydata[,-6])
clusters = seq(1,10)
#for (x in clusters){}
#km = kmeans(training, x, iter.max = 10, nstart = 1)
km = kmeans(training, 5, iter.max = 10, nstart = 1)
km = kmeans(training, 5, iter.max = 10, 5)
View(mydata)
training = mydata[-1,-6]
View(training)
km = kmeans(training, 5, iter.max = 10, 5)
View(training)
mydata = mydata[],-1]
mydata = mydata[,-1]
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[,-1]
response = data.frame(m
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[,-1]
response = data.frame(mydata[,5])
training = mydata[,-5]
View(mydata)
training = mydata[-1,-5]
View(training)
View(response)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
response = data.frame(mydata[,5])
training = mydata[-1,-5]
View(training)
View(response)
View(mydata)
km = kmeans(training, 5, iter.max = 10, 5)
clusters = seq(1,10)
#for (x in clusters){}
#km = kmeans(training, x, iter.max = 10, nstart = 1)
km = kmeans(training, 5, iter.max = 10, 5)
km = kmeans(training, 5, iter.max = 10,  nstart = 5)
km = kmeans(training, 1, iter.max = 10,  nstart = 1)
km = kmeans(training, 2, iter.max = 10,  nstart = 2)
View(response)
View(training)
training = mydata[,-5]
km = kmeans(training, 2, iter.max = 10,  nstart = 2)
km = kmeans(training, centers = 2, iter.max = 10,  nstart = 2)
)
km = kmeans(training, centers = 2, iter.max = 10)
km = kmeans(training, centers = 2, iter.max = 10)
View(training)
View(response)
View(mydata)
View(response)
View(training)
training = double(mydata[,-5])
View(training)
View(response)
class(training)
class(training[,1])
class(training[,2])
class(training[,3])
class(training[1,1])
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
response = data.frame(mydata[,5])
training = data.matrix(mydata[,-5])
clusters = seq(2,10)
#for (x in clusters){
#km = kmeans(training, x, iter.max = 10, nstart = 1)
km = kmeans(training, centers = 2, iter.max = 10)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(2, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, x, iter.max = 10)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(2, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, 2, iter.max = 10)
View(km)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(2, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, 2, iter.max = 10)
km.clusters
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(2, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, 2, iter.max = 10)
km.cluster
cluster
km$cluster
clusters = seq(1, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, 1, iter.max = 10)
km$cluster
View(training)
training = data.matrix(mydata[1:, -5])
training = data.matrix(mydata[:, -5])
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
View(response)
View(training)
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(1, 10)
df = data.frame()
row = 1
#for (x in clusters) {
#km = kmeans(training, x, iter.max = 10)
km = kmeans(training, 1, iter.max = 10)
km$cluster
group = tr(km$cluster)
group
group = t(km$cluster)
group
df[,2] = km$cluster[,2]
df[1] = km$cluster
df[,1] = km$cluster
mx = matrix(,nrow = nrow(training). ncol = length(clusters))
mx = matrix(,nrow = nrow(training), ncol = length(clusters))
mx[,1] = km$cluster
View(mx)
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1, -1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[, -5])
clusters = seq(1, 10)
mx = matrix(,nrow = nrow(training), ncol = length(clusters))
col = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
#km = kmeans(training, 1, iter.max = 10)
mx[,x] = km$cluster}
View(mx)
distance[x,]= km$tot.withinss
distance = matrix(,nrow = nrow(training), 1)
distance[x,]= km$tot.withinss
source('~/Bryson/Github/ISYE/Homework 2/HW-4dot1.R', echo=TRUE)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 4.1
#install.packages("stats")
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = nrow(training), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
#km = kmeans(training, 1, iter.max = 10)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
View(distance)
library(stats)
rm(list = ls())
mydata = data.frame(read.csv("iris.csv", header = FALSE)) #read in data
mydata = mydata[-1,-1]
rownames(mydata) = 1:nrow(mydata)
response = data.frame(mydata[, 5])
training = data.matrix(mydata[,-5])
clusters = seq(1, 10)
resp = matrix(, nrow = nrow(training), ncol = length(clusters))
distance = matrix(, nrow = length(clusters), 1)
y = 1
for (x in clusters) {
km = kmeans(training, x, iter.max = 10)
resp[, x] = km$cluster
distance[x, ] = km$tot.withinss
}
View(distance)
#Bryson Cook
#ISYE6501, Spring 2018
#Homework 2
#Part 3.1a
#install.packages("kknn")
rm(list = ls())
library(kknn)
mydata = data.frame(read.csv("credit_card_data.csv", header = FALSE)) #read in data
groups = 10 #10 groups
gs = round(nrow(mydata) / groups, 0) #number of rows per group
steps = seq(1, 20)  #number of neighbors to try
answery = matrix(, length(steps), ncol = groups)
for (y in seq(1, groups)) {
#outer loop to split data into k subsets for crossvalidation
start = 1 + (gs * y) - gs
stop = y * gs
if (y == groups) {
stop = nrow(mydata) #So the last group will include any remainder rows
}
training = mydata[-(start:stop), ] #selects all data except the kth group for training
validation = mydata[(start:stop), ]  #selects the kth group of data for the validation data
z = 1
for (i in steps) {
#second loop to iterate through neighbor values
answerx = matrix(, nrow(validation), ncol = 1)
for (x in 1:nrow(validation)) {
#inner loop to sweep through data set
knn = kknn(V11 ~ .,
training,
validation[x, ],
k = i,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == validation[x, 11]
answerx[x, 1] = match
total = sum(answerx)
}
accuracy = total / nrow(validation)
answery[z, y] = accuracy
z = z + 1
}
}
Best_K_Value = which.max(rowMeans(answery))  #This will chose the training set with the higherst accuracy, thus the best K-NN Value
Best_K_Value
plot(
steps,
rowMeans(answery),
main = "K-Nearest Neighbor Accuracies",
xlab = "k Values",
ylab = "Accuracy"
)
answer_final = matrix(, nrow(mydata), ncol = 1)
for (x in 1:nrow(mydata)) {
knn = kknn(V11 ~ ., mydata[-x, ], mydata[x, ],
k = Best_K_Value,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == test[x, 11]
answer_final[x, 1] = match
}
final_accuracy = sum(answer_final) / nrow(mydata)
final_accuracy
for (x in 1:nrow(mydata)) {
knn = kknn(V11 ~ ., mydata[-x, ], mydata[x, ],
k = Best_K_Value,
scale = TRUE)
class = round(fitted(knn), 0)
match = class == mydata[x, 11]
answer_final[x, 1] = match
}
final_accuracy = sum(answer_final) / nrow(mydata)
final_accuracy
